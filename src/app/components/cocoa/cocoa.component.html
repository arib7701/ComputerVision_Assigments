<header id="jumbo" class="grid">
  <div class="backimg"></div>
  <div class="content-jumbo">
    <h1>Image Classification with Transfer Learning</h1>
    <p>Coding Assignment #4 - Spring 2018</p>
    <a class="btn" [routerLink]="['/']">Go Back</a>
  </div>
</header>
<div class="container">
  <section class="row">
    <div class="col-md-12 col-sm-12">
      <h3>Introduction:</h3>
      <p>
        This final project objective is to use the concept of deep learning to
        classify the content of images. Object classification has been largely
        improved recently with the growing availability of computational and
        space capacity via the cloud. Neural Network can be used to their full
        capabilities to understand and classify images content. <br /><br />
        In this project, we use a Convolutional Neural Network to classify to
        type of content in images: Healthy Cocoa Pod and Sick Cocoa Pod.
      </p>
    </div>

    <div class="cocoaEx col-md-12 col-sm-12">
      <img src="../../../assets/images/cocoa/healthyPod.png" alt="healthyPod" />
      <img src="../../../assets/images/cocoa/sickPod.png" alt="sickPod" />
    </div>
  </section>
  <hr class="style1" />
  <section class="row">
    <div class="col-md-12 col-sm-12">
      <h3>Motivations:</h3>
      <p>
        The current boom of Deep learning has enable a lot of projects in a
        various range of subjects and disciplines. A lot of codes, tutorials and
        forums are available online to help in the building of classification
        projects. In terms of Computer Vision, Deep Learning algorithm has
        improved by far understanding of images content.

        <br /><br />
        Having previously earned a master’s degree in agriculture, it always has
        been my interest to merge the two fields of Agriculture and Computer
        Science in the same long-term project. Moreover, my previous experiences
        in West Africa specifically in Ghana, has confronted me with numerous
        problems in the agriculture sector. Agriculture represents the largest
        employer and contributor to the GPD in the West African region. In
        particular, cocoa production is one of the main source of revenue within
        the agriculture sector. However, in the recent years, producers have
        been confronted with an increase of diseases which has led to
        significant loss in production. Unlike other cash crops, cocoa diseases
        often require total alienation of cocoa trees. As a consequence, farmers
        lose substantial capital. Thus, early detection of diseases is
        primordial in the management of plantation to minimize farmers losses.

        <br /><br />
        Project like this one could bring an effective and cheap detection tool
        to local farmer via the use of smartphones (which numbers are booming on
        the continent) and could have a real impact of cocoa production
        efficiency.
        <br />
      </p>
    </div>
  </section>
  <hr />
  <section class="row">
    <div class="dataset col-md-12 col-sm-12">
      <h4>Datasets</h4>
      <p style="text-align: left">
        In order to run a deep learning algorithm on images, we need images, a
        lot of images. Within the given time and the topic of the projects, it
        has not been possible to find a real and consequent database of cocoa
        pods and we have not been able to collect real images from the fields.
        All images used in this project have been found via three main sources:
        Google Images, Flicker and
        <a href="http://www.image-net.org/" target="_blank">ImageNet database</a
        >. <br /><br />
        <li>
          ImageNet <br />
          After a bit of research, it appeared that the ImageNet Database had
          around 700 of classified cocoa pods. However, there were barely any
          sick or diseased pods in the associated folder (and if any, they were
          all mixed up).
        </li>
        <br />
        <li>
          Google Image / Flicker Scrapping <br />
          We used some python code to scrapped images from Google Images and
          Flicker to collect the rest of the dataset. Many images collected were
          irrelevant or duplicates and a lot of cleaning had to be done in order
          to obtain a correct dataset.
        </li>
      </p>
    </div>

    <div class="datasetImg col-md-12 col-sm-12">
      <img
        src="../../../assets/images/cocoa/healthyPodsDataset.png"
        alt="healthyPodsDataset"
      />
    </div>
    <div class="dataset col-md-12 col-sm-12">
      <p>
        However, the set of collected sick cocoa pods images was quite thin.
        Some cropping and duplication using Paint have been done to enlarge the
        number of images. For example, when two pods were found in one image,
        each pod was cropped and saved as its own image.
        <br /><br />
        In the end, our images have been separated in two folders: Healthy and
        Sick. A total of 1,400 images have been collected for the Healthy
        category and a bit more than 700 images have been found for the Sick
        category.
      </p>
    </div>
    <div class="datasetImg col-md-12 col-sm-12">
      <img
        src="../../../assets/images/cocoa/sickPodsDataset.png"
        alt="sickPodsDataset"
      />
    </div>
  </section>
  <hr class="style1" />
  <section class="row">
    <div class="col-md-12 col-sm-12 ">
      <h4>Challenges</h4>
      <p style="text-align: left">
        <li>
          Diseases diversity <br />The first difficulty is the numerous types of
          diseases which can affect cocoa pods and cocoa tree: Black Pod,
          Witches Broom, Frosty Pod Rot, Swollen Shoot Virus, etc. Images found
          of sick pods or sick trees have not been well documented and without
          expertise classification of sickness could not be done as this step of
          the project. Furthermore, in order to obtain good results in Deep
          Learning project, it is primordial to have a very large number of
          pictures available. Our 1400 and 700 images (for healthy and sick
          category respectively), are definitely not enough to run a
          Convolutional Neural Network from scratch. Therefore, it was
          impossible for this project to classify in detail the type of disease
          involved in the pictures. We reduced thus our project to a binary
          classification: healthy/sick.
        </li>
        <br />
        <li>
          Small Datasets <br />Subsequently, due to a rather quite small
          dataset, our Deep Learning model has a very high probability of
          overfitting the results to our training set. Fortunately, techniques
          exist to our advantage (see methodology) to avoid or at least reduce
          the overfitting problem.
        </li>
        <br />
        <li>
          Smartphone application<br />Lastly, the ultimate challenge regards the
          final use of the model via smartphone. The end goal is to produce a
          smartphone application which can correctly classifies healthy and sick
          pods. The use of smartphones brings two limitations to the model:
          first its need to be relatively small in terms of memory and
          computation (during prediction) to be able to run on a phone in just a
          few seconds without freezing the rest of the device. Secondly, the
          model must be able to classify on low resolutions images taken from
          the device. Those two limitations have not been looked at in this
          current project but can maybe be overcome in the future by using
          technologies like Android Tensorflow API for the memory and
          computational issue and by training our model on lower resolutions
          images in the future.
        </li>
      </p>
    </div>
  </section>
  <hr class="style1" />
  <section class="row ">
    <div class="col-md-7 col-sm-12 ">
      <h4>Normalized Cut Method</h4>
      <p>
        An image can be seen as a fully connected graph, where each pixel is a
        node, which is linked to each other pixel by edges (weighted)
        representing the similarity between a pair. This graph can be split into
        different groups by minimizing the value of the cut i.e. cutting
        (removing) the edges with the minimum weight (i.e. minimum similarity).
        Normalized Cut computed the cost as a fraction of the total edge
        connections to all the nodes in the graph. Finding the optimal partition
        is an NP-complete problem, but an approximate solution was found using
        the eigenvalues and eigenvectors.
        <br />
        <br />
        First we compute the symmetric weight matrix W which represents the
        similarity measure between each pair of pixel. We use two features: the
        spatial location and the RGB color value of a pixel. The similarity is
        measured using the squared Euclidean distance. Next, W is transformed
        into a diagonal matrix D. Then we find the eigenvalues of D minus W.
        Using the second smallest eigenvalues, we use its associated
        eigenvectors to solve the cut and bi-partition the graph. We then
        iterate using the same steps and recursion until we reach a minimum area
        for each partition. Once all the partitions are created, we have to
        assemble them again and apply the mean color obtained to each specific
        partition.
        <br />
        <br />
        Normalized Cut implementation by Naotoshi Seo, can be found in Matlab
        <a
          href="http://note.sonots.com/SciSoftware/NcutImageSegmentation.html"
          target="_blank"
          >here</a
        >.
      </p>
    </div>

    <div class="col-md-5 col-sm-12 ">
      <img
        id="downimg1 "
        src="../../../assets/images/segmentation/peppers200_NCut.jpg "
        alt="peppersNCut "
      />
    </div>
  </section>
  <hr class="style1" />
  <section class="row examples">
    <h4 class="col-md-12 col-sm-12">
      Others Examples (Original / KMeans / Mean Shift / Normalized Cut)
    </h4>
    <div class="col-md-12">
      <div class="segmentationEx col-md-12 col-sm-12">
        <img src="../../../assets/images/segmentation/lena.jpg" alt="lena" />
        <img
          src="../../../assets/images/segmentation/lena_KMeansSegmentation_10.jpg"
          alt="lena_Kmeans"
        />
        <img
          src="../../../assets/images/segmentation/lena200_MeanShift0.1Spatial.jpg"
          alt="lena_MeanShit"
        />
        <img
          src="../../../assets/images/segmentation/lena200_NCut.jpg"
          alt="lena_NCut"
        />
      </div>
      <div class="segmentationEx col-md-12 col-sm-12">
        <img src="../../../assets/images/segmentation/hand.jpg" alt="hand" />
        <img
          src="../../../assets/images/segmentation/hand200_KMeansSegmentation_6.jpg"
          alt="hand_Kmeans"
        />
        <img
          src="../../../assets/images/segmentation/hand200_MeanShift0.1Spatial.jpg"
          alt="hand_MeanShit"
        />
        <img
          src="../../../assets/images/segmentation/hand200_NCut.jpg"
          alt="hand_NCut"
        />
      </div>
      <div class="segmentationEx col-md-12 col-sm-12">
        <img
          src="../../../assets/images/segmentation/pilou300.jpg"
          alt="pilou"
        />
        <img
          src="../../../assets/images/segmentation/pilou250_KMeansSegmentation_6.jpg"
          alt="pilou_Kmeans"
        />
        <img
          src="../../../assets/images/segmentation/pilou250_MeanShift0.1Spatial.jpg"
          alt="pilou_MeanShit"
        />
        <img
          src="../../../assets/images/segmentation/pilou250_NCut.jpg"
          alt="pilou_NCut"
        />
      </div>
      <div class="segmentationEx col-md-12 col-sm-12">
        <img
          src="../../../assets/images/segmentation/Sighisoara.jpg"
          alt="Sighisoara"
        />
        <img
          src="../../../assets/images/segmentation/Sighisoara250_KMeansSegmentation_8.jpg"
          alt="sighisoara_Kmeans"
        />
        <img
          src="../../../assets/images/segmentation/Sighisoara250_MeanShift0.1Spatial.jpg"
          alt="sighisoara_MeanShit"
        />
        <img
          src="../../../assets/images/segmentation/Sighisoara250_NCut.jpg"
          alt="sighisoara_NCut"
        />
      </div>
      <div class="segmentationEx col-md-12 col-sm-12">
        <img
          src="../../../assets/images/segmentation/campus.jpg"
          alt="campus"
        />
        <img
          src="../../../assets/images/segmentation/campus200_KMeansSegmentation_6.jpg"
          alt="campus_Kmeans"
        />
        <img
          src="../../../assets/images/segmentation/campus200_MeanShift0.1Spatial.jpg"
          alt="campus_MeanShit"
        />
        <img
          src="../../../assets/images/segmentation/campus200_NCut.jpg"
          alt="campus_NCut"
        />
      </div>
    </div>
  </section>
  <hr class="style1" />
  <section class="row">
    <div class="concept col-md-12 col-sm-12">
      <h4>Pros & Cons</h4>
      <p>
        <b>K-Means:</b>
        <br />
        The main advantage of the K-means is that it’s a very simple method to
        implement and to understand. It also converges quite rapidly to local
        minimums. However, it does have some disadvantages. It requires a bit of
        memory since each pixel must be compared to each cluster at each
        iteration. As well, the user needs to pick the number of clusters as a
        parameter. Evaluating the number of cluster can be difficult for image
        segmentation. Also, the result will depend on the initialization of the
        cluster center. Different run of the algorithm will give different
        results since the centers are randomly chosen. The results will be
        depending on outliers too. Outliers will deform what could be defined as
        a normal cluster by a human eye. Finally, K-Means tends to only find
        spherical cluster and have a lot of difficulties with intertwined
        shapes. In the image experiments, the results show a good segmentation
        in all the case. However, the segmentation is sometimes too precise
        compared to some Mean-Shift results.
        <br />
        <br />
        <b>Normalized Cut:</b>
        <br />
        The main advantage of this method is that is based on a graph structure
        which have been well implemented. As well, the weight matrix can be
        computed in different way and may incorporate different types of
        features. It does not require a data distribution model. It has several
        disadvantages. The first one is the very high time and space complexity
        of the algorithm. For pictures of 512x512, the weight matrix will have a
        size of 262144x262144, which is quite important, mostly if the matrix is
        dense and not sparse. From that matrix, we have to find the eigenvalues,
        which proves to be quite a challenge for large matrix. It was the big
        issue in my implementation. As well, the algorithm when completed has a
        tendency to prefer balanced clusters in size, which can pause inaccuracy
        in the segmentation. Finally, the parameters of the implementation have
        a very high importance in the results. Some parameters will not allow
        the complete computation of the eigenvalues, and some parameters will
        give a very poor segmentation. In my image experiments, it was very
        difficult to find the right combinations of parameters to get good
        results. The results showed below are the best I could get and in my
        view are not as good as the K-Means and Mean-Shift results.
        <br />
        <br />
        <b>Mean Shift:</b>
        <br />
        The main advantage of the Mean Shift is that is find automatically the
        main peaks of attraction in the image. It also does not require more
        than one parameter (i.e. the window size). It’s a simple technique which
        can find multiple nodes in a relative small computational time. Also, it
        does not produce same size or specific shape on clusters. In the image
        experiments, the mean shift with spatial information produces in my
        opinion the best results. The clusters are more defined than in the
        Normalized Cut but are more averaging than with a K-Means
        implementation. The main disadvantage is that we still have to choose a
        parameter (the window size). Figuring the best window size can be
        difficult. As well, Mean-Shift does not scale well with high dimensions
        of the feature space.
      </p>
    </div>
  </section>
</div>

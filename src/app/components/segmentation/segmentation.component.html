<header id="jumbo" class="grid">
  <div class="backimg"></div>
  <div class="content-jumbo">
    <h1>Image Segmentation</h1>
    <p>Coding Assignment #3 - Spring 2018</p>
    <a class="btn" [routerLink]="['/']">Go Back</a>
  </div>
</header>
<div class="container">
  <section class="row">
    <div class="col-md-12 col-sm-12">
      <h3>Image Segmentation Concepts:</h3>
      <p>In computer vision, image segmentation is the process of partitioning a digital image into multiple segments (sets
        of pixels, also known as super-pixels). The goal of segmentation is to simplify and/or change the representation
        of an image into something that is more meaningful and easier to analyze.
        <br>
        <br> Image segmentation is typically used to locate objects and boundaries (lines, curves, etc.) in images. More precisely,
        image segmentation is the process of assigning a label to every pixel in an image such that pixels with the same
        label share certain characteristics. Each of the pixels in a region are similar with respect to some characteristic
        or computed property, such as color, intensity, or texture. Adjacent regions are significantly different with respect
        to the same characteristic(s).
        <br/>
        <br> We are going to explore three different methods to realize image segmentation: K-Means, Mean Shift and Normalized
        Cut.
    </div>
    <div class="segmentationEx col-md-12 col-sm-12">
      <img src="../../../assets/images/segmentation/peppers.jpg" alt="peppersOriginal">
      <img src="../../../assets/images/segmentation/peppers_KMeansSegmentation_6.jpg" alt="peppersKmeans">
      <img src="../../../assets/images/segmentation/peppers200_MeanShift0.1.jpg" alt="peppersMeanShift">
      <img src="../../../assets/images/segmentation/peppers200_NCut.jpg" alt="peppersNCut">
    </div>
  </section>
  <hr class="style1">
  <section class="row">
    <div class="col-md-7 col-sm-12">
      <h3>K-Means Method:</h3>
      <p>K-Means is a clustering algorithm based on pair-similarity or pair-dissimilarity where similar data are gather in the
        same cluster and different data into different clusters. In our implementation the similarity measurement is the
        color of the pixel. Pixels with nearly the same color should be gathered into the same cluster. The algorithm is
        implemented in three main parts:
        <ol>
          <li>Create the clusters centers randomly (the number of clusters is a parameter that must be chosen at the beginning)</li>
          <li>
            Loop until there is convergence:
            <ul>
              <li>Calculate the color distances between all the pixels and each clusters center</li>
              <li>Assign pixels to their closest clusters centers (using the lowest color distance)</li>
              <li>Re-compute the mean of the clusters centers to get their new color value</li>
            </ul>
          </li>
          <li> Apply the final clusters to the image</li>
        </ol>
        <br>
        <br>Below is my own implemenation of KMeans in C++ and OpenCv.
    </div>
    <div class="col-md-5 col-sm-12">
      <img src="../../../assets/images/segmentation/peppers_KMeansSegmentation_6.jpg" alt="peppersKmeans">
    </div>
  </section>
  <hr>
  <section class="row">
    <div class="concept col-md-4 col-sm-12">
      <h4>Step 1: Initialization</h4>
      <p>The first step is the initialization of the clusters. The user must first set up the number of desired clusters. This
        is the only parameter of the algorithm. The clusters centers are selected randomly using the RNG random function
        of OpenCV. Each cluster is defined by an RGB value, which will be sued in the second step..</p>
    </div>
    <div class="concept col-md-4 col-sm-12">
      <h4>Step 2: Loop</h4>
      <p>In a loop, which stops when the clusters centers values stop changing, the color distance is computing between each
        pixel and each cluster center. To measure the color distance, we use the Euclidean distance between the RGB value
        of the pixel and the cluster center. For each pixel, we find the cluster with the minimum color distance and attached
        the pixel to it. Once each cluster center has a list of pixels, we use their color values to re-compute the mean
        value and new color value of the cluster. Using the difference between the old value and the new value we check if
        the threshold to stop the loop is reached.</p>
    </div>
    <div class="concept col-md-4 col-sm-12">
      <h4>Step 3: Application</h4>
      <p> In the last steps, we have obtained the final color values of each cluster centers. We have to assign this value to
        all the pixels associated their specific clusters centers. However, in order to see the results better, we decided
        to assign a random color value to each cluster (instead of the mean value).</p>
    </div>
    <div class="fctImg col-md-4 col-sm-12">
      <img src="../../../assets/images/segmentation/KMeans_InitFct.png" alt="Kmean_InitFct">
    </div>
    <div class="fctImg col-md-4 col-sm-12">
      <img src="../../../assets/images/segmentation/KMeans_DistanceFct.png" alt="Kmean_DistanceFct">
    </div>
    <div class="fctImg col-md-4 col-sm-12">
      <img src="../../../assets/images/segmentation/KMeans_AppliFct.png" alt="Kmean_AppliFct">
    </div>
  </section>
  <hr class="style1">
  <section class="row">
    <div class="col-md-7 col-sm-12 ">
      <h4>Mean Shift Method</h4>
      <p></p>The Mean Shift algorithm clusters image using some features of the pixel. Mean Shift uses a specified sized window
      to find the points of highest density (peaks) among the data and then performs a mean shift for each window until it
      reaches convergence. Once convergence is found for every window, it merges windows that ends up at the same peak.
      <br>
      <br> First, the different features (color and location) are set into a unique matrix. After initialization, a loop, is
      used to set a ramdom mean shift location. The next step calculates the squared distance between each pixel not assigned
      yet and the mean. If the distance is less than the bandwidth, then the pixel will be associated to the current cluster.
      Finally, the mean value is adjusted in function of its associated pixels. Each pixel of the clusters is set to inactive,
      so they are not used in the next iteration. The process is repeated until convergence. If another cluster with nearly
      the same mean is found, then the two clusters are merged together. The loop stops when all the pixels have been assigned
      to a cluster. At the end of the algorithm, the clusters are represented on the image with the associated mean color
      value.
      <br>
      <br> Mean Shift implementation by Bryan Feldman, can be found in Matlab
      <a href="https://www.mathworks.com/matlabcentral/fileexchange/10161-mean-shift-clustering" target="_blank">here</a>.
    </div>
    <div class="col-md-5 col-sm-12 ">
      <img src="../../../assets/images/segmentation/peppers200_MeanShift0.1.jpg " alt="peppersMeanShift ">
    </div>
  </section>
  <hr class="style1">
  <section class="row ">
    <div class="col-md-7 col-sm-12 ">
      <h4>Normalized Cut Method</h4>
      <p>An image can be seen as a fully connected graph, where each pixel is a node, which is linked to each other pixel by
        edges (weighted) representing the similarity between a pair. This graph can be split into different groups by minimizing
        the value of the cut i.e. cutting (removing) the edges with the minimum weight (i.e. minimum similarity). Normalized
        Cut computed the cost as a fraction of the total edge connections to all the nodes in the graph. Finding the optimal
        partition is an NP-complete problem, but an approximate solution was found using the eigenvalues and eigenvectors.
        <br>
        <br> First we compute the symmetric weight matrix W which represents the similarity measure between each pair of pixel.
        We use two features: the spatial location and the RGB color value of a pixel. The similarity is measured using the
        squared Euclidean distance. Next, W is transformed into a diagonal matrix D. Then we find the eigenvalues of D minus
        W. Using the second smallest eigenvalues, we use its associated eigenvectors to solve the cut and bi-partition the
        graph. We then iterate using the same steps and recursion until we reach a minimum area for each partition. Once
        all the partitions are created, we have to assemble them again and apply the mean color obtained to each specific
        partition.
        <br>
        <br> Normalized Cut implementation by Naotoshi Seo, can be found in Matlab
        <a href="http://note.sonots.com/SciSoftware/NcutImageSegmentation.html" target="_blank">here</a>.
    </div>
    <div class="col-md-5 col-sm-12 ">
      <img id="downimg1 " src="../../../assets/images/segmentation/peppers200_NCut.jpg " alt="peppersNCut ">
    </div>
  </section>
  <hr class="style1">
  <section class="row examples">
    <h4 class="col-md-12 col-sm-12">Others Examples (Original / KMeans / Mean Shift / Normalized Cut)</h4>
    <div class="col-md-12">
      <div class="segmentationEx col-md-12 col-sm-12">
        <img src="../../../assets/images/segmentation/lena.jpg" alt="lena">
        <img src="../../../assets/images/segmentation/lena_KMeansSegmentation_10.jpg" alt="lena_Kmeans">
        <img src="../../../assets/images/segmentation/lena200_MeanShift0.1Spatial.jpg" alt="lena_MeanShit">
        <img src="../../../assets/images/segmentation/lena200_NCut.jpg" alt="lena_NCut">
      </div>
      <div class="segmentationEx col-md-12 col-sm-12">
        <img src="../../../assets/images/segmentation/hand.jpg" alt="hand">
        <img src="../../../assets/images/segmentation/hand200_KMeansSegmentation_6.jpg" alt="hand_Kmeans">
        <img src="../../../assets/images/segmentation/hand200_MeanShift0.1Spatial.jpg" alt="hand_MeanShit">
        <img src="../../../assets/images/segmentation/hand200_NCut.jpg" alt="hand_NCut">
      </div>
      <div class="segmentationEx col-md-12 col-sm-12">
        <img src="../../../assets/images/segmentation/pilou300.jpg" alt="pilou">
        <img src="../../../assets/images/segmentation/pilou250_KMeansSegmentation_6.jpg" alt="pilou_Kmeans">
        <img src="../../../assets/images/segmentation/pilou250_MeanShift0.1Spatial.jpg" alt="pilou_MeanShit">
        <img src="../../../assets/images/segmentation/pilou250_NCut.jpg" alt="pilou_NCut">
      </div>
      <div class="segmentationEx col-md-12 col-sm-12">
        <img src="../../../assets/images/segmentation/Sighisoara.jpg" alt="Sighisoara">
        <img src="../../../assets/images/segmentation/Sighisoara250_KMeansSegmentation_8.jpg" alt="sighisoara_Kmeans">
        <img src="../../../assets/images/segmentation/Sighisoara250_MeanShift0.1Spatial.jpg" alt="sighisoara_MeanShit">
        <img src="../../../assets/images/segmentation/Sighisoara250_NCut.jpg" alt="sighisoara_NCut">
      </div>
      <div class="segmentationEx col-md-12 col-sm-12">
        <img src="../../../assets/images/segmentation/campus.jpg" alt="campus">
        <img src="../../../assets/images/segmentation/campus200_KMeansSegmentation_6.jpg" alt="campus_Kmeans">
        <img src="../../../assets/images/segmentation/campus200_MeanShift0.1Spatial.jpg" alt="campus_MeanShit">
        <img src="../../../assets/images/segmentation/campus200_NCut.jpg" alt="campus_NCut">
      </div>
    </div>
  </section>
  <hr class="style1">
  <section class="row">
    <div class="concept col-md-12 col-sm-12">
      <h4>Pros & Cons</h4>
      <p>
        <b>K-Means:</b>
        <br> The main advantage of the K-means is that it’s a very simple method to implement and to understand. It also converges
        quite rapidly to local minimums. However, it does have some disadvantages. It requires a bit of memory since each
        pixel must be compared to each cluster at each iteration. As well, the user needs to pick the number of clusters
        as a parameter. Evaluating the number of cluster can be difficult for image segmentation. Also, the result will depend
        on the initialization of the cluster center. Different run of the algorithm will give different results since the
        centers are randomly chosen. The results will be depending on outliers too. Outliers will deform what could be defined
        as a normal cluster by a human eye. Finally, K-Means tends to only find spherical cluster and have a lot of difficulties
        with intertwined shapes. In the image experiments, the results show a good segmentation in all the case. However,
        the segmentation is sometimes too precise compared to some Mean-Shift results.
        <br>
        <br>
        <b>Normalized Cut:</b>
        <br> The main advantage of this method is that is based on a graph structure which have been well implemented. As well,
        the weight matrix can be computed in different way and may incorporate different types of features. It does not require
        a data distribution model. It has several disadvantages. The first one is the very high time and space complexity
        of the algorithm. For pictures of 512x512, the weight matrix will have a size of 262144x262144, which is quite important,
        mostly if the matrix is dense and not sparse. From that matrix, we have to find the eigenvalues, which proves to
        be quite a challenge for large matrix. It was the big issue in my implementation. As well, the algorithm when completed
        has a tendency to prefer balanced clusters in size, which can pause inaccuracy in the segmentation. Finally, the
        parameters of the implementation have a very high importance in the results. Some parameters will not allow the complete
        computation of the eigenvalues, and some parameters will give a very poor segmentation. In my image experiments,
        it was very difficult to find the right combinations of parameters to get good results. The results showed below
        are the best I could get and in my view are not as good as the K-Means and Mean-Shift results.
        <br>
        <br>
        <b>Mean Shift:</b>
        <br> The main advantage of the Mean Shift is that is find automatically the main peaks of attraction in the image. It
        also does not require more than one parameter (i.e. the window size). It’s a simple technique which can find multiple
        nodes in a relative small computational time. Also, it does not produce same size or specific shape on clusters.
        In the image experiments, the mean shift with spatial information produces in my opinion the best results. The clusters
        are more defined than in the Normalized Cut but are more averaging than with a K-Means implementation. The main disadvantage
        is that we still have to choose a parameter (the window size). Figuring the best window size can be difficult. As
        well, Mean-Shift does not scale well with high dimensions of the feature space.
      </p>
    </div>
  </section>
</div>